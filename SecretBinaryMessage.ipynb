{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPq3IyxWWsdBSw/5PAPrbap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wickstrom/ssl-summer-school-dtu/blob/main/SecretBinaryMessage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title generate secret message (this takes a little while).\n",
        "\n",
        "indices_of_secret_message = [740, 192, 1009, 394, 831, 481, 335, 1015, 1025, 166, 747, 361, 32, 142, 962, 1006, 333, 398, 1022, 178, 868, 292, 734, 64, 147, 377, 236, 347, 773, 594, 446, 795, 849, 304, 388, 588, 710, 171, 622, 517, 716, 534, 977, 513, 16, 605, 1021, 796, 196, 909, 626, 152, 142, 716, 1004, 515, 112, 1000, 68, 388, 198, 228, 486, 509, 629, 854, 149, 12, 776, 695, 940, 748, 146, 995, 730, 749, 819, 561, 511, 377, 97, 467, 637, 478, 835, 900, 990, 320, 365, 841, 749, 86, 987, 173, 365, 362, 477, 484, 646, 565, 168, 893, 789, 915, 577, 562, 616, 66, 160, 729, 863, 427, 326, 880, 373, 153, 32, 155, 350, 857, 866, 652, 109, 867, 91, 384, 1010, 571, 307, 839, 179, 142, 383, 672, 918, 333, 273, 572, 22, 854, 70, 751, 50, 247, 112, 362, 381, 638, 923, 892, 162, 656, 1011, 266, 931, 620, 447, 567, 392, 140, 769, 669, 802, 372, 730, 661, 739, 921, 572, 1020, 324, 553, 989, 478, 437, 1031, 718, 320, 997, 419, 365, 892, 589, 908, 328, 523, 993, 748, 39, 689, 873, 775, 179, 477, 909, 791, 163, 670, 121, 54, 172, 362, 311, 984, 947, 475, 696, 688, 948, 753, 875, 500, 146, 412, 943, 938, 326, 157, 1026, 268, 348, 237, 266, 365, 548, 874, 225, 353, 475, 421, 532, 949, 932, 800, 406, 1025, 178, 770, 935, 860, 742, 333, 839, 112, 28, 950, 691, 666, 53, 750, 347, 914, 567, 684, 149, 533, 831, 188, 756, 965, 992, 90, 493, 693, 705, 286, 70, 1044, 57, 192, 385, 22, 18, 736, 668, 847, 363, 862, 625, 680, 511, 775, 451, 632, 532, 993, 813, 918, 804, 490, 352, 522, 338, 761, 597, 899, 40, 910, 714, 698, 281, 1044, 866, 403, 383, 1043, 314, 265, 381, 896, 225, 277, 108, 323, 413, 581, 799, 408, 1049, 885, 161, 810, 707, 522, 775, 942, 395, 411, 847, 226, 507, 289, 301, 364, 109, 411, 1008, 575, 417, 821, 457, 314, 453, 583, 974, 131, 18, 705, 417, 723, 1023, 800, 388, 485, 472, 275, 941, 552, 778, 1043, 121, 332, 969, 203, 858, 746, 520, 453, 1047, 379, 339, 400, 702, 380, 195, 188, 379, 188, 696, 677, 662, 160, 945, 873, 835, 633, 638, 450, 715, 22, 184, 837, 629, 1021, 673, 302, 941, 38, 416, 853, 916, 55, 1036, 49, 34, 179, 168, 506, 122, 290, 193, 4, 6, 694, 610, 144, 12, 479, 155, 550, 261, 765, 408, 371, 454, 99, 392, 988, 697, 271, 973, 912, 62, 622, 891, 727, 369, 653, 852, 898, 606, 827, 911, 131, 878, 898, 548, 219, 617, 902, 235, 722, 798, 528, 930, 839, 971, 767, 47, 495, 354, 487, 691, 866, 454, 538, 880, 937, 722, 595, 521, 472, 800, 517, 1025, 469, 638, 884, 332, 638, 721, 897, 967, 1038, 490, 813, 88, 754, 152, 788, 1007, 830, 694, 288, 471, 691, 714, 273, 669, 75, 28, 129, 101, 306, 584, 969, 193, 674, 596, 248, 207, 703, 728, 162, 346, 57, 385, 636, 772, 521, 110, 687, 548, 763, 413, 935, 814, 315, 132, 691, 493, 968, 520, 720, 798, 351, 842, 460, 1021, 765, 794, 244, 556, 728, 914, 757, 589, 616, 503, 98, 111, 509, 347]\n",
        "\n",
        "import torch\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "training_data = MNIST('/sample_data/', train=True, download=True, transform=ToTensor())\n",
        "all_test_data = MNIST('/sample_data/', train=False, download=True, transform=ToTensor())\n",
        "validation_data, test_data = torch.utils.data.random_split(all_test_data, [5000, 5000])\n",
        "\n",
        "training_loader = DataLoader(training_data, shuffle=False, batch_size=1)\n",
        "validation_loader = DataLoader(validation_data, shuffle=False, batch_size=1)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=1)\n",
        "\n",
        "binary_training_images = []\n",
        "binary_training_labels = []\n",
        "\n",
        "binary_validation_images = []\n",
        "binary_validation_labels = []\n",
        "\n",
        "binary_test_images = []\n",
        "binary_test_labels = []\n",
        "\n",
        "for x, y in training_loader:\n",
        "    if y.item() == 0:\n",
        "        binary_training_images.append(x)\n",
        "        binary_training_labels.append(y)\n",
        "\n",
        "for x, y in training_loader:\n",
        "    if y.item() == 1:\n",
        "        binary_training_images.append(x)\n",
        "        binary_training_labels.append(y)\n",
        "\n",
        "for x, y in validation_loader:\n",
        "    if y.item() == 0:\n",
        "        binary_validation_images.append(x)\n",
        "        binary_validation_labels.append(y)\n",
        "\n",
        "for x, y in validation_loader:\n",
        "    if y.item() == 1:\n",
        "        binary_validation_images.append(x)\n",
        "        binary_validation_labels.append(y)\n",
        "\n",
        "for x, y in test_loader:\n",
        "    if y.item() == 0:\n",
        "        binary_test_images.append(x)\n",
        "        binary_test_labels.append(y)\n",
        "\n",
        "for x, y in test_loader:\n",
        "    if y.item() == 1:\n",
        "        binary_test_images.append(x)\n",
        "        binary_test_labels.append(y)\n",
        "\n",
        "binary_training_data = TensorDataset(torch.cat(binary_training_images), torch.cat(binary_training_labels))\n",
        "binary_validation_data = TensorDataset(torch.cat(binary_validation_images), torch.cat(binary_validation_labels))\n",
        "binary_test_data = TensorDataset(torch.cat(binary_test_images), torch.cat(binary_test_labels))\n",
        "\n",
        "binary_training_loader = DataLoader(binary_training_data, shuffle=True, batch_size=100)\n",
        "binary_validation_loader = DataLoader(binary_validation_data, shuffle=False, batch_size=1)\n",
        "binary_test_loader = DataLoader(binary_test_data, shuffle=False, drop_last=False, batch_size=100)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for counter in range(6):\n",
        "    secret_message_component_i = indices_of_secret_message[counter]\n",
        "    plt.subplot(1, 6, counter+1)\n",
        "    plt.imshow(binary_validation_data.tensors[0][secret_message_component_i].squeeze())\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "zVAMG6MppFKL",
        "outputId": "0f531807-791c-4b35-a4b7-307438efb4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create AI to solve task and train it.\n",
        "\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "class LeNet(torch.nn.Module):\n",
        "    \"\"\"Network architecture from: https://github.com/ChawDoe/LeNet5-MNIST-PyTorch.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_1 = torch.nn.Conv2d(1, 25, 5)\n",
        "        self.pool_1 = torch.nn.MaxPool2d(2, 2)\n",
        "        self.relu_1 = torch.nn.ReLU()\n",
        "        self.conv_2 = torch.nn.Conv2d(25, 50, 5)\n",
        "        self.pool_2 = torch.nn.MaxPool2d(2, 2)\n",
        "        self.relu_2 = torch.nn.ReLU()\n",
        "        self.fc_1 = torch.nn.Linear(800, 120)\n",
        "        self.relu_3 = torch.nn.ReLU()\n",
        "        self.fc_2 = torch.nn.Linear(120, 84)\n",
        "        self.relu_4 = torch.nn.ReLU()\n",
        "        self.fc_3 = torch.nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool_1(self.relu_1(self.conv_1(x)))\n",
        "        x = self.pool_2(self.relu_2(self.conv_2(x)))\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.relu_3(self.fc_1(x))\n",
        "        x = self.relu_4(self.fc_2(x))\n",
        "        x = self.fc_3(x)\n",
        "        return x\n",
        "\n",
        "    def softmax_forward(self, x):\n",
        "        x = x.unsqueeze(0)\n",
        "        return torch.nn.functional.softmax(self.forward(x), dim=1)\n",
        "\n",
        "model = LeNet()\n",
        "\n",
        "def train_model(model,\n",
        "                train_data: torchvision.datasets,\n",
        "                test_data: torchvision.datasets,\n",
        "                device: torch.device,\n",
        "                epochs: int,\n",
        "                criterion: torch.nn,\n",
        "                optimizer: torch.optim,\n",
        "                evaluate: bool):\n",
        "    \"\"\"Train torch model.\"\"\"\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for images, labels in train_data:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluate model!\n",
        "        if evaluate:\n",
        "            predictions, labels = evaluate_model(model, test_data, device)\n",
        "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, data, device):\n",
        "    \"\"\"Evaluate torch model.\"\"\"\n",
        "    model.eval()\n",
        "    logits = torch.Tensor().to(device)\n",
        "    targets = torch.LongTensor().to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits = torch.cat([logits, model(images)])\n",
        "            targets = torch.cat([targets, labels])\n",
        "\n",
        "    return torch.nn.functional.softmax(logits, dim=1), targets\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = train_model(model=model.to(device),\n",
        "                    train_data=binary_training_loader,\n",
        "                    test_data=binary_test_loader,\n",
        "                    device=device,\n",
        "                    epochs=10,\n",
        "                    criterion=torch.nn.CrossEntropyLoss().to(device),\n",
        "                    optimizer=torch.optim.Adam(model.parameters()),\n",
        "                    evaluate=True)\n",
        "\n",
        "# Model to GPU and eval mode.\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Check test set performance.\n",
        "predictions, labels = evaluate_model(model, binary_test_loader, device)\n",
        "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
        "print(f\"Model test accuracy: {(100 * test_acc):.2f}%\")"
      ],
      "metadata": {
        "id": "xyzzPbV4LYro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1cb935-315e-462e-8fdc-f275e08033df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - test accuracy: 99.90% and CE loss 0.00\n",
            "Epoch 2/10 - test accuracy: 100.00% and CE loss 0.00\n",
            "Epoch 3/10 - test accuracy: 99.90% and CE loss 0.00\n",
            "Epoch 4/10 - test accuracy: 100.00% and CE loss 0.00\n",
            "Epoch 5/10 - test accuracy: 100.00% and CE loss 0.00\n",
            "Epoch 6/10 - test accuracy: 99.90% and CE loss 0.00\n",
            "Epoch 7/10 - test accuracy: 100.00% and CE loss 0.00\n",
            "Epoch 8/10 - test accuracy: 100.00% and CE loss 0.00\n",
            "Epoch 9/10 - test accuracy: 100.00% and CE loss 0.00\n",
            "Epoch 10/10 - test accuracy: 100.00% and CE loss 0.00\n",
            "Model test accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Funksjoner for å klassifisere og vise bilder.\n",
        "\n",
        "def classify_image(index_of_image_in_database):\n",
        "    componenent_to_decode = binary_validation_data.tensors[0][index_of_image_in_database].unsqueeze(0)\n",
        "    predicted_component = model(componenent_to_decode.to(device)).argmax(1).item()\n",
        "    return predicted_component\n",
        "\n",
        "def plot_image(index_of_image_in_database):\n",
        "    plt.figure(1)\n",
        "    plt.imshow(binary_validation_data.tensors[0][index_of_image_in_database].squeeze())\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "aJ-ToSCmPGg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Første oppgave: ta et element fra listen \"indices_of_secret_message\" og putt det inn i funksjonen \"classify_image\"\n"
      ],
      "metadata": {
        "id": "Q3WMoTNBO6G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Andre oppgave: ta et element fra listen \"indices_of_secret_message\" og putt det inn i funksjonen \"plot_image\"\n"
      ],
      "metadata": {
        "id": "64tB5wvwRtyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tredje oppgave: klassifiser alle bildene i \"indices_of_secret_message\"\n",
        "\n",
        "# Dette er en litt vanskeligere oppgave. Først, lag en tom list, f.eks.\n",
        "# \"classified_images = []\". Deretter, lag en for loop som går\n",
        "# igjennom hele listen \"indices_of_secret_message\". For hvert element i listen,\n",
        "# bruk funksjonen \"classify_image\" og append resultatet til \"classified_images\".\n"
      ],
      "metadata": {
        "id": "hnG6b-YuQDHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Funksjoner for å konvertere til en binær beskjed og for å konvertere fra binær til tekst.\n",
        "\n",
        "def convert_classified_images_to_binary_message(classified_images):\n",
        "    binary_secret_message = ''\n",
        "\n",
        "    for counter, secret_message_component_i in enumerate(classified_images):\n",
        "        if counter % 7 == 0 and counter != 0:\n",
        "            binary_secret_message = binary_secret_message + ' '\n",
        "            binary_secret_message = binary_secret_message + str(secret_message_component_i)\n",
        "        else:\n",
        "            binary_secret_message = binary_secret_message + str(secret_message_component_i)\n",
        "    return binary_secret_message\n",
        "\n",
        "def binary_to_string(binary_string):\n",
        "    return ''.join(chr(int(x, 2)) for x in binary_string.split())\n"
      ],
      "metadata": {
        "id": "960i4wlwStqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fjerde oppgave: konverter \"binary_secret_message\" inn i convert_classified_images_to_binary_message\n",
        "\n",
        "# Dette er en litt vanskeligere oppgave. Først, lag en tom list, f.eks.\n",
        "# \"binary_secret_message = []\". Deretter, lag en for loop som går\n",
        "# igjennom hele listen \"indices_of_secret_message\". For hvert element i listen,\n",
        "# bruk funksjonen \"classify_image\" og append resultatet til \"binary_secret_message\".\n",
        "\n"
      ],
      "metadata": {
        "id": "1MeoFbjDT1an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Siste oppgave: dekod den hemmelige beskjed ved å bruke \"binary_to_string\" funksjonen.\n",
        "\n",
        "# Hva er den hemmelige beskjeden? Kanskje du må bruke Google for å få hint til\n",
        "# hva beskjeden sikter til.\n",
        "\n",
        "# Tips: Det er ikke sikkert AIen gjør en perfekt jobb, og noen deler av koden\n",
        "# kan være feil-klassifisert.\n",
        "\n"
      ],
      "metadata": {
        "id": "k-LlNuD3capG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQFqR6QHWV64"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}